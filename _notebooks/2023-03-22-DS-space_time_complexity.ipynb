{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Structures- Space and Time Complexity\n",
    "> Observing the time complexity of different algorithms\n",
    "- toc: true\n",
    "- image: /images/python.png\n",
    "- categories: []\n",
    "- type: pbl\n",
    "- week: 27"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space and Time Complexity\n",
    "> Space complexity refers to the amount of memory used by an algorithm to complete its execution, as a function of the size of the input. The space complexity of an algorithm can be affected by various factors such as the size of the input data, the data structures used in the algorithm, the number and size of temporary variables, and the recursion depth. Time complexity refers to the amount of time required by an algorithm to run as the input size grows. It is usually measured in terms of the \"Big O\" notation, which describes the upper bound of an algorithm's time complexity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Why do you think a programmer should care about space and time complexity?\n",
    "- They need to care because they want their program to run efficiently and in the quickest time possible. It can help create optimal conditions and therefore, make us better coders. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at our lassen volcano example from the data compression tech talk. The first code block is the original image. In the second code block, change the baseWidth to rescale the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from pathlib import Path \n",
    "\n",
    "# prepares a series of images\n",
    "def image_data(path=Path(\"images/\"), images=None):  # path of static images is defaulted\n",
    "    for image in images:\n",
    "        # File to open\n",
    "        image['filename'] = path / image['file']  # file with path\n",
    "    return images\n",
    "\n",
    "def image_display(images):\n",
    "    for image in images:  \n",
    "        display(Image(filename=image['filename']))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lassen_volcano = image_data(images=[{'source': \"Peter Carolin\", 'label': \"Lassen Volcano\", 'file': \"lassen-volcano.jpg\"}])\n",
    "    image_display(lassen_volcano)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "from pathlib import Path \n",
    "from PIL import Image as pilImage \n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "# prepares a series of images\n",
    "def image_data(path=Path(\"images/\"), images=None):  # path of static images is defaulted\n",
    "    for image in images:\n",
    "        # File to open\n",
    "        image['filename'] = path / image['file']  # file with path\n",
    "    return images\n",
    "\n",
    "def scale_image(img):\n",
    "    #baseWidth = 625\n",
    "    #baseWidth = 1250\n",
    "    #baseWidth = 2500\n",
    "    baseWidth = 5000 # see the effect of doubling or halfing the baseWidth \n",
    "    #baseWidth = 10000 \n",
    "    #baseWidth = 20000\n",
    "    #baseWidth = 40000\n",
    "    scalePercent = (baseWidth/float(img.size[0]))\n",
    "    scaleHeight = int((float(img.size[1])*float(scalePercent)))\n",
    "    scale = (baseWidth, scaleHeight)\n",
    "    return img.resize(scale)\n",
    "\n",
    "def image_to_base64(img, format):\n",
    "    with BytesIO() as buffer:\n",
    "        img.save(buffer, format)\n",
    "        return base64.b64encode(buffer.getvalue()).decode()\n",
    "    \n",
    "def image_management(image):  # path of static images is defaulted        \n",
    "    # Image open return PIL image object\n",
    "    img = pilImage.open(image['filename'])\n",
    "    \n",
    "    # Python Image Library operations\n",
    "    image['format'] = img.format\n",
    "    image['mode'] = img.mode\n",
    "    image['size'] = img.size\n",
    "    image['width'], image['height'] = img.size\n",
    "    image['pixels'] = image['width'] * image['height']\n",
    "    # Scale the Image\n",
    "    img = scale_image(img)\n",
    "    image['pil'] = img\n",
    "    image['scaled_size'] = img.size\n",
    "    image['scaled_width'], image['scaled_height'] = img.size\n",
    "    image['scaled_pixels'] = image['scaled_width'] * image['scaled_height']\n",
    "    # Scaled HTML\n",
    "    image['html'] = '<img src=\"data:image/png;base64,%s\">' % image_to_base64(image['pil'], image['format'])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Use numpy to concatenate two arrays\n",
    "    images = image_data(images = [{'source': \"Peter Carolin\", 'label': \"Lassen Volcano\", 'file': \"lassen-volcano.jpg\"}])\n",
    "    \n",
    "    # Display meta data, scaled view, and grey scale for each image\n",
    "    for image in images:\n",
    "        image_management(image)\n",
    "        print(\"---- meta data -----\")\n",
    "        print(image['label'])\n",
    "        print(image['source'])\n",
    "        print(image['format'])\n",
    "        print(image['mode'])\n",
    "        print(\"Original size: \", image['size'], \" pixels: \", f\"{image['pixels']:,}\")\n",
    "        print(\"Scaled size: \", image['scaled_size'], \" pixels: \", f\"{image['scaled_pixels']:,}\")\n",
    "        \n",
    "        print(\"-- original image --\")\n",
    "        display(HTML(image['html'])) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Do you think this is a time complexity or space complexity or both problem? \n",
    "- Both because as the images increase in size, not only does space become an issue, but so does time. In addition, vscode couldn't even render the image in the end, ultimately proving that this function is bad for normal computers. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big O Notation\n",
    "- Constant O(1)\n",
    "- Linear O(n)\n",
    "- Quadratic O(n^2) \n",
    "- Logarithmic O(logn)\n",
    "- Exponential (O(2^n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n"
     ]
    }
   ],
   "source": [
    "#create a list called numbers with 1,000 numbers in it\n",
    "numbers = list(range(1000))\n",
    "print(numbers)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant O(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n",
    "> An example of a constant time algorithm is accessing a specific element in an array. It does not matter how large the array is, accessing an element in the array takes the same amount of time. Therefore, the time complexity of this operation is constant, denoted by O(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n",
      "Alabama\n"
     ]
    }
   ],
   "source": [
    "#prints the number at index 263\n",
    "print(numbers[263])\n",
    "\n",
    "ncaa_bb_ranks = {1:\"Alabama\",2:\"Houston\", 3:\"Purdue\", 4:\"Kansas\"}\n",
    "#look up a value in a dictionary given a key\n",
    "print(ncaa_bb_ranks[1]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space\n",
    "> This function takes two number inputs and returns their sum. The function does not create any additional data structures or variables that are dependent on the input size, so its space complexity is constant, or O(1). Regardless of how large the input numbers are, the function will always require the same amount of memory to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that takes the sum of two numbers\n",
    "def sum(a, b): \n",
    "  return a + b\n",
    "\n",
    "print(sum(90,88))\n",
    "print(sum(.9,.88))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear O(n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n",
    "> An example of a linear time algorithm is traversing a list or an array. When the size of the list or array increases, the time taken to traverse it also increases linearly with the size. Hence, the time complexity of this operation is O(n), where n is the size of the list or array being traversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterates through the numbers list \n",
    "for i in numbers:\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space\n",
    "> This function takes a list of elements arr as input and returns a new list with the elements in reverse order. The function creates a new list reversed_arr of the same size as arr to store the reversed elements. The size of reversed_arr depends on the size of the input arr, so the space complexity of this function is O(n). As the input size increases, the amount of memory required to execute the function also increases linearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_list(arr):\n",
    "    n = len(arr) \n",
    "    reversed_arr = [None] * n #create a list of None based on the length or arr\n",
    "    for i in range(n):\n",
    "        reversed_arr[n-i-1] = arr[i] #stores the value at the index of arr to the value at the index of reversed_arr starting at the beginning for arr and end for reversed_arr \n",
    "    return reversed_arr\n",
    "\n",
    "print(numbers)\n",
    "print(reverse_list(numbers))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic O(n^2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n",
    "> An example of a quadratic time algorithm is nested loops. When there are two nested loops that both iterate over the same collection, the time taken to complete the algorithm grows quadratically with the size of the collection. Hence, the time complexity of this operation is O(n^2), where n is the size of the collection being iterated over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterates through the list twice creating a nested loop\n",
    "for i in numbers:\n",
    "    for j in numbers:\n",
    "        print(i,j)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space\n",
    "> This function takes two matrices matrix1 and matrix2 as input and returns their product as a new matrix. The function creates a new matrix result with dimensions m by n to store the product of the input matrices. The size of result depends on the size of the input matrices, so the space complexity of this function is O(n^2). As the size of the input matrices increases, the amount of memory required to execute the function also increases quadratically."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example of Matrix Multiplication](images/multiply_matrices.png)\n",
    "\n",
    "- Main take away is that a new matrix is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_matrices(matrix1, matrix2):\n",
    "    m = len(matrix1) \n",
    "    n = len(matrix2[0])\n",
    "    result = [[0] * n] * m #this creates the new matrix based on the size of matrix 1 and 2\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            for k in range(len(matrix2)):\n",
    "                result[i][j] += matrix1[i][k] * matrix2[k][j]\n",
    "    return result\n",
    "\n",
    "print(multiply_matrices([[1,2],[3,4]], [[3,4],[1,2]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logarithmic O(logn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n",
    "> An example of a log time algorithm is binary search. Binary search is an algorithm that searches for a specific element in a sorted list by repeatedly dividing the search interval in half. As a result, the time taken to complete the search grows logarithmically with the size of the list. Hence, the time complexity of this operation is O(log n), where n is the size of the list being searched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n"
     ]
    }
   ],
   "source": [
    "#function used to search for a target using a binary search\n",
    "def binary_search(arr, low, high, target):\n",
    "    while low <= high:\n",
    "        mid = (low + high) // 2 #integer division\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid - 1\n",
    "\n",
    "target = 263\n",
    "result = binary_search(numbers, 0, len(numbers) - 1, target)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space\n",
    "> The same algorithm above has a O(logn) space complexity. The function takes an array arr, its lower and upper bounds low and high, and a target value target. The function searches for target within the bounds of arr by recursively dividing the search space in half until the target is found or the search space is empty. The function does not create any new data structures that depend on the size of arr. Instead, the function uses the call stack to keep track of the recursive calls. Since the maximum depth of the recursive calls is O(logn), where n is the size of arr, the space complexity of this function is O(logn). As the size of arr increases, the amount of memory required to execute the function grows logarithmically."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential O(2^n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n",
    "> An example of an O(2^n) algorithm is the recursive implementation of the Fibonacci sequence. The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones, starting from 0 and 1. The recursive implementation of the Fibonacci sequence calculates each number by recursively calling itself with the two preceding numbers until it reaches the base case (i.e., the first or second number in the sequence). The algorithm takes O(2^n) time in the worst case because it has to calculate each number in the sequence by making two recursive calls."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A visualization of calculating the fibonacci sequence](images/fibonacci.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832040\n"
     ]
    }
   ],
   "source": [
    "#recrursive function to calculate the fibonacci number at n\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "#print(fibonacci(5))\n",
    "#print(fibonacci(10))\n",
    "#print(fibonacci(20))\n",
    "print(fibonacci(30))\n",
    "#print(fibonacci(40))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space\n",
    "> This function takes a set s as input and generates all possible subsets of s. The function does this by recursively generating the subsets of the set without the first element, and then adding the first element to each of those subsets to generate the subsets that include the first element. The function creates a new list for each recursive call that stores the subsets, and each element in the list is a new list that represents a subset. The number of subsets that can be generated from a set of size n is 2^n, so the space complexity of this function is O(2^n). As the size of the input set increases, the amount of memory required to execute the function grows exponentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [1, 2], [1, 3], [1], [2, 3], [2], [3], []]\n"
     ]
    }
   ],
   "source": [
    "def generate_subsets(s):\n",
    "    if not s:\n",
    "        return [[]]\n",
    "    subsets = generate_subsets(s[1:])\n",
    "    return [[s[0]] + subset for subset in subsets] + subsets\n",
    "\n",
    "print(generate_subsets([1,2,3]))\n",
    "#print(generate_subsets(numbers))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using the time library, we are able to see the difference in time it takes to calculate the fibonacci function above.\n",
    "- Based on what is known about the other time complexities, hypothesize the resulting elapsed time if the function is replaced. \n",
    "\n",
    "The difference in timing between the functions seems to be based upon the mathematical multipliers associated. For example, in the exponential case below, the time will likely be close to double the previous because the product is continuously multipled by 2 for each n.\n",
    "\n",
    "For logarithmic, the difference in timing would likely be less extreme as time goes on, since logarithm functions grow longer more than they do greater. It makes sense that quadratic gets greater and greater as n increases, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "print(fibonacci(34))\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(\"Time taken:\", total_time, \"seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(fibonacci(35))\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(\"Time taken:\", total_time, \"seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacks\n",
    "- Record your findings when testing the time elapsed of the different algorithms.\n",
    "- Although we will go more in depth later, time complexity is a key concept that relates to the different sorting algorithms. Do some basic research on the different types of sorting algorithms and their time complexity.\n",
    "- Why is time and space complexity important when choosing an algorithm?\n",
    "\n",
    "Time and space complexity are important when choosing an algorithm because they determine how much time and memory an algorithm will require to solve a problem. An algorithm that is efficient in terms of time and space complexity will be faster and require less memory than an algorithm that is not efficient, making it a better choice for solving larger problems or problems that need to be solved quickly.\n",
    "\n",
    "If the algorithm doesn't work, this is bad from both the perspective of a programmer and of a consumer. A consumer does not want to work with a laggy, slow program that fails to account for large amounts of data and programmers will find it difficult to work around processing algorithms that are very time-consuming.\n",
    "\n",
    "\n",
    "- Should you always use a constant time algorithm / Should you never use an exponential time algorithm? Explain? \n",
    "\n",
    "No, you should not always use a constant time algorithm or never use an exponential time algorithm. The choice of algorithm depends on the specific problem being solved and the trade-offs between time and space complexity. In some cases, a constant time algorithm may not be able to solve the problem efficiently, while in other cases, an exponential time algorithm may be the only practical solution. It is important to consider the constraints and requirements of the problem at hand when choosing an algorithm.\n",
    "\n",
    "\n",
    "- What are some general patterns that you noticed to determine each algorithm's time and space complexity?\n",
    "\n",
    "Some general patterns to determine time and space complexity are analyzing loops, recursive functions, and nested data structures. For time complexity, counting the number of operations executed by an algorithm related to/caused by the input size is often used to determine time complexity. For space complexity, analyzing the amount of memory required to store data as a function of the input size is often used to determine space complexity.\n",
    "\n",
    "Complete the Time and Space Complexity analysis questions linked below.\n",
    "[Practice](https://www.geeksforgeeks.org/practice-questions-time-complexity-analysis/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - What is the time and space complexity of the following code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "for i in range(N):\n",
    "  a = a + random()\n",
    " \n",
    "for i in range(M):\n",
    "  b = b + random()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. O(N * M) time, O(1) space\n",
    "2. O(N + M) time, O(N + M) space\n",
    "3. O(N + M) time, O(1) space\n",
    "4. O(N * M) time, O(N + M) space\n",
    "\n",
    "My answer: 3 (Correct)\n",
    "\n",
    "Reasoning: The two for loops are linear O(N) and O(M) respectively, but because they aren't nested, the time complexity isn't described by multiplying N and M. Instead, it would be O(N + M). The variables' sizes are singular and not affected by the size of the input, so the space complexity can be represented as O(1) (linear)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - What is the time complexity of the following code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(N):\n",
    "  for j in reversed(range(i,N)):\n",
    "    a = a + i + j"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. O(N)\n",
    "2. O(N*log(N))\n",
    "3. O(N * Sqrt(N))\n",
    "4. O(N*N)\n",
    "My answer: 4 (Correct)\n",
    "\n",
    "Reasoning: These are nested for loops, which were the exact example of quadratic time complexity we learned in class, so I was pretty easily able to identify it as quadratic (O(N*N))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - What is the time complexity of the following code?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. O(n)\n",
    "2. O(nlog(n))\n",
    "3. O(n^2)\n",
    "4. O(n^2(log(n)))\n",
    "My answer: 2 (Correct)\n",
    "\n",
    "Reasoning: I knew the first loop was linear, but the second one seemed like it was doing something like moving up in powers of two, like log with a base of 2. So, the time complexity was O(n * log(2)(n)) or O(nlog(n))."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: What does it mean when we say that an algorithm X is asymptotically more efficient than Y?\n",
    "\n",
    "1. X will always be a better choice for small inputs\n",
    "2. X will always be a better choice for large inputs\n",
    "3. Y will always be a better choice for small inputs\n",
    "4. X will always be a better choice for all inputs\n",
    "\n",
    "My answer: 2 (Correct)\n",
    "\n",
    "Reasoning: I had to look up \"asymptoticallly\" to figure it out. Now I know that it means that X is more efficient than Y when a number n is greater than a certain limiting (positive) constant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 - What is the time complexity of the following code?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. O(N)\n",
    "2. O(Sqrt(N))\n",
    "3. O(N / 2)\n",
    "4. O(log N)\n",
    "My answer: 4 (Correct)\n",
    "\n",
    "Reasoning: This was a weird one again because it seemed to resemble the log base 2 example from before, but hasn't been phrased as a while loop yet. Ultimately, I made an educated answer, but not a completely confident one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6 - Which of the following best describes the useful criterion for comparing the efficiency of algorithms?\n",
    "1. Time\n",
    "2. Memory\n",
    "3. Both of the above\n",
    "4. None of the above\n",
    "My answer: 3 (Correct)\n",
    "\n",
    "Reasoning: This is just a basic concept that we learned from the lesson."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7 - How is time complexity measured?\n",
    "\n",
    "1. By counting the number of algorithms in an algorithm.\n",
    "2. By counting the number of primitive operations performed by the algorithm on a given input size.\n",
    "3. By counting the size of data input to the algorithm.\n",
    "4. None of the above\n",
    "My answer: 2 (Correct)\n",
    "\n",
    "Reasoning: This just sounded like a textbook definition, though I didn't know what it meant by \"primitive.\" I knew it wasn't counting the size of the data, and I knew it wasn't as simple as just counting the number of algorithms."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8 - What will be the time complexity of the following code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "  i=i*k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. O(n)\n",
    "2. O(k)\n",
    "3. O(logk(n))\n",
    "4. O(logn(k))\n",
    "My answer: 3 (Correct)\n",
    "\n",
    "Reasoning: Mathematically, it only makes sense to be 3. It couldn't be linear like 1 or 2, since the variable i, which dictates the continued run of the program, is being multiplied by k. In this case, another way to explain the program is that it loops until k has multiplied by itself enough to reach n, which describes how a point would be reached in a logarithmic graph."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9 - What is the time complexity of the following code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 0\n",
    "for i in range(n):\n",
    "  for j in range(i):\n",
    "    value=value+1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. O(n)\n",
    "2. O(n+1)\n",
    "3. O(n(n-1))\n",
    "4. O(n(n+1))\n",
    "My answer: 4 (wrong)\n",
    "\n",
    "Correct answer: 3\n",
    "\n",
    "Reasoning: I had never seen a loop like this before and I wasn't really clear on how I could convert it to Big O notation. Now that I think about it more, range function makes n the ceiling that could never be reached. If n was 2, for example, I would end up being 0 and 1, but never 2. For that reason, O(n * (n - 1)) does make sense."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10 - Algorithm A and B have a worst-case running time of O(n) and O(logn), respectively. Therefore, algorithm B always runs faster than algorithm A.\n",
    "\n",
    "1. True\n",
    "2. False\n",
    "My answer: 2 (Correct)\n",
    "\n",
    "Reasoning: Part of why I gave this answer is that whenever \"always runs faster\" is asked in conjunction to a question about time complexity, I will say false. But it's also because, though I'm not familiar with \"worst-case running time,\" I know that linear algorithms (according to my tests) can sometimes be faster with logarithmic ones, especially working with smaller n values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
